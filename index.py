# -*- coding: utf-8 -*-
"""ai in finance

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l-nGbcpupDb0ikG9yYkBIid6CwufSN7o

# Finding the credit score
"""

# Install required packages
!pip install google-generativeai plotly pandas numpy scikit-learn textblob

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import google.generativeai as genai
import ipywidgets as widgets
from IPython.display import display, HTML, clear_output
import warnings
warnings.filterwarnings('ignore')

# Configure Gemini API
genai.configure(api_key='AIzaSyCh_KSVD79FXNUortR5sz8uPP4wLGGWldk')
model = genai.GenerativeModel('gemini-pro')

class MicrofinanceAnalyzer:
    def __init__(self):
        self.scaler = StandardScaler()
        self.risk_model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.is_trained = False

    def generate_training_data(self, n_samples=1000):
        """Generate synthetic training data"""
        data = {
            # Financial Metrics
            'credit_score': np.random.randint(300, 850, n_samples),
            'income': np.random.lognormal(10.5, 0.5, n_samples),
            'business_age': np.random.uniform(0, 20, n_samples),
            'sector_growth_rate': np.random.uniform(-0.1, 0.3, n_samples),

            # ESG Metrics
            'renewable_energy_usage': np.random.uniform(0, 1, n_samples),
            'community_impact': np.random.uniform(0, 1, n_samples),
            'waste_management': np.random.uniform(0, 1, n_samples),

            # Digital & Behavioral
            'digital_adoption': np.random.uniform(0, 1, n_samples),
            'payment_consistency': np.random.uniform(0, 1, n_samples),
            'online_presence': np.random.uniform(0, 1, n_samples),

            # Operational
            'operational_efficiency': np.random.uniform(0, 1, n_samples),
            'automation_level': np.random.uniform(0, 1, n_samples)
        }

        # Calculate risk score
        risk_factors = (
            0.3 * (1 - (data['credit_score'] - 300) / 550) +
            0.2 * (1 - data['payment_consistency']) +
            0.2 * (1 - data['operational_efficiency']) +
            0.15 * (1 - data['digital_adoption']) +
            0.15 * (20 - data['business_age']) / 20
        )

        data['risk_level'] = (risk_factors > 0.5).astype(int)
        return pd.DataFrame(data)

    def train(self):
        """Train the model"""
        # Generate and prepare training data
        train_data = self.generate_training_data()
        X = train_data.drop('risk_level', axis=1)
        y = train_data['risk_level']

        # Fit scaler and model
        self.scaler.fit(X)
        X_scaled = self.scaler.transform(X)
        self.risk_model.fit(X_scaled, y)
        self.is_trained = True

        return "Model trained successfully!"

    def analyze_application(self, features):
        """Analyze loan application"""
        if not self.is_trained:
            self.train()

        # Prepare features
        features_df = pd.DataFrame([features])
        features_scaled = self.scaler.transform(features_df)

        # Get risk prediction
        risk_prob = self.risk_model.predict_proba(features_scaled)[0][1]

        # Calculate component scores
        scores = {
            'Financial Health': (1 - risk_prob) * 100,
            'ESG Score': self._calculate_esg_score(features),
            'Digital Readiness': self._calculate_digital_score(features),
            'Operational Efficiency': self._calculate_efficiency_score(features)
        }

        # Generate recommendations
        recommendations = self._generate_recommendations(scores, features)

        # Get AI insights
        insights = self._get_ai_insights(scores, features)

        return {
            'scores': scores,
            'recommendations': recommendations,
            'insights': insights
        }

    def _calculate_esg_score(self, features):
        return (
            features['renewable_energy_usage'] * 0.4 +
            features['community_impact'] * 0.4 +
            features['waste_management'] * 0.2
        ) * 100

    def _calculate_digital_score(self, features):
        return (
            features['digital_adoption'] * 0.5 +
            features['online_presence'] * 0.5
        ) * 100

    def _calculate_efficiency_score(self, features):
        return (
            features['operational_efficiency'] * 0.6 +
            features['automation_level'] * 0.4
        ) * 100

    def _generate_recommendations(self, scores, features):
        avg_score = np.mean(list(scores.values()))

        if avg_score >= 75:
            return {
                'loan_type': 'Premium Growth Loan',
                'amount': f"${features['income'] * 3:,.0f}",
                'rate': '8-10%',
                'features': ['Flexible repayment', 'Business credit line', 'Digital banking integration']
            }
        elif avg_score >= 60:
            return {
                'loan_type': 'Standard Business Loan',
                'amount': f"${features['income'] * 2:,.0f}",
                'rate': '11-13%',
                'features': ['Fixed repayment', 'Business mentoring']
            }
        else:
            return {
                'loan_type': 'Micro Business Loan',
                'amount': f"${features['income']:,.0f}",
                'rate': '14-16%',
                'features': ['Financial literacy training', 'Basic digital tools']
            }

    def _get_ai_insights(self, scores, features):
        prompt = f"""
        Analyze this business loan application and provide 3 key insights in simple language:

        Scores:
        - Financial Health: {scores['Financial Health']:.1f}
        - ESG Score: {scores['ESG Score']:.1f}
        - Digital Readiness: {scores['Digital Readiness']:.1f}
        - Operational Efficiency: {scores['Operational Efficiency']:.1f}

        Business Profile:
        - Age: {features['business_age']:.1f} years
        - Sector Growth: {features['sector_growth_rate']*100:.1f}%
        - Digital Adoption: {features['digital_adoption']*100:.1f}%

        Focus on strength, areas for improvement, and growth potential.
        """

        response = model.generate_content(prompt)
        return response.text

def create_dashboard():
    """Create interactive dashboard"""
    analyzer = MicrofinanceAnalyzer()
    analyzer.train()  # Train the model immediately

    print("MicroFinance AI Platform")
    print("------------------------")

    # Create input widgets
    widgets_data = {
        'credit_score': ('slider', 'Credit Score', 300, 850, 650),
        'income': ('slider', 'Annual Income', 10000, 200000, 50000),
        'business_age': ('slider', 'Business Age (years)', 0, 20, 5),
        'sector_growth_rate': ('slider', 'Sector Growth Rate', -0.1, 0.3, 0.1),
        'renewable_energy_usage': ('slider', 'Renewable Energy Usage', 0, 1, 0.5),
        'community_impact': ('slider', 'Community Impact', 0, 1, 0.5),
        'waste_management': ('slider', 'Waste Management Score', 0, 1, 0.5),
        'digital_adoption': ('slider', 'Digital Adoption Level', 0, 1, 0.6),
        'payment_consistency': ('slider', 'Payment Consistency', 0, 1, 0.7),
        'online_presence': ('slider', 'Online Presence', 0, 1, 0.5),
        'operational_efficiency': ('slider', 'Operational Efficiency', 0, 1, 0.6),
        'automation_level': ('slider', 'Automation Level', 0, 1, 0.5)
    }

    input_widgets = {}
    for name, (type_, label, min_, max_, default) in widgets_data.items():
        if type_ == 'slider':
            input_widgets[name] = widgets.FloatSlider(
                value=default,
                min=min_,
                max=max_,
                description=label
            )

    # Display widgets
    for widget in input_widgets.values():
        display(widget)

    analyze_button = widgets.Button(description='Analyze Application')
    display(analyze_button)

    def on_analyze_click(b):
        clear_output(wait=True)

        features = {name: widget.value for name, widget in input_widgets.items()}
        results = analyzer.analyze_application(features)

        # Create visualization
        fig = make_subplots(
            rows=2, cols=2,
            specs=[[{'type': 'indicator'}, {'type': 'bar'}],
                  [{'type': 'pie'}, {'type': 'table'}]],
            subplot_titles=('Overall Score', 'Component Scores',
                          'Score Distribution', 'Recommendations')
        )

        # Overall score gauge
        overall_score = np.mean(list(results['scores'].values()))
        fig.add_trace(
            go.Indicator(
                mode="gauge+number",
                value=overall_score,
                title={'text': "Overall Score"},
                gauge={'axis': {'range': [0, 100]}},
            ),
            row=1, col=1
        )

        # Component scores bar chart
        fig.add_trace(
            go.Bar(
                x=list(results['scores'].keys()),
                y=list(results['scores'].values()),
                name="Component Scores"
            ),
            row=1, col=2
        )

        # Score distribution pie chart
        fig.add_trace(
            go.Pie(
                labels=list(results['scores'].keys()),
                values=list(results['scores'].values()),
                name="Score Distribution"
            ),
            row=2, col=1
        )

        # Recommendations table
        rec = results['recommendations']
        fig.add_trace(
            go.Table(
                header=dict(values=['Feature', 'Value']),
                cells=dict(values=[
                    ['Loan Type', 'Amount', 'Interest Rate', 'Features'],
                    [
                        rec['loan_type'],
                        rec['amount'],
                        rec['rate'],
                        '<br>'.join(rec['features'])
                    ]
                ])
            ),
            row=2, col=2
        )

        fig.update_layout(height=800, showlegend=False)
        fig.show()

        # Display AI insights
        print("\nAI Analysis Insights:")
        print(results['insights'])

    analyze_button.on_click(on_analyze_click)

# Run the dashboard
create_dashboard()

"""# Financial insights and recomendations"""

import google.generativeai as genai

# Set up Gemini API
GEMINI_API_KEY = "AIzaSyCh_KSVD79FXNUortR5sz8uPP4wLGGWldk"
genai.configure(api_key=GEMINI_API_KEY)

class MicrofinanceCreditAnalyzer:
    def __init__(self):
        pass

    def _assess_creditworthiness(self, data):
        """Basic credit score calculation"""
        on_time_payments = sum(1 for p in data['utility_payments'] if p['on_time'])
        missed_payments = len(data['utility_payments']) - on_time_payments
        payment_ratio = on_time_payments / len(data['utility_payments']) if data['utility_payments'] else 0
        credit_score = int(payment_ratio * 100)
        return max(30, min(credit_score, 100))

    def _generate_gemini_insights(self, data):
        """Use Gemini AI to provide insights on borrower financial stability"""
        prompt = f"""
        Analyze the following borrower data and provide key financial insights:
        {data}
        """
        model = genai.GenerativeModel("gemini-pro")
        response = model.generate_content(prompt)
        return response.text

    def analyze_borrower(self, data):
        """Comprehensive borrower analysis"""
        credit_score = self._assess_creditworthiness(data)
        gemini_insights = self._generate_gemini_insights(data)

        analysis = {
            'scores': {'Alternative Credit Score': credit_score},
            'insights': gemini_insights
        }
        return analysis

# Sample borrower data
borrower_data = {
    'utility_payments': [{'on_time': True}, {'on_time': False}, {'on_time': True}],
    'mobile_payments': [{'status': 'completed'}, {'status': 'failed'}],
    'business_age': 3,
    'revenue_stability': 0.6,
    'sector_growth': 0.7
}

# Run analysis
analyzer = MicrofinanceCreditAnalyzer()
analysis = analyzer.analyze_borrower(borrower_data)
print("Gemini Insights:", analysis['insights'])

"""# Credit risk prediction"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc

# 1. Generate Synthetic Data
np.random.seed(0)
data_size = 1000
credit_scores = np.random.normal(600, 100, data_size)
annual_incomes = np.abs(np.random.normal(50000, 15000, data_size))  # Ensure positive values
loan_amounts = np.abs(np.random.normal(20000, 7000, data_size))
collateral_values = np.abs(np.random.normal(25000, 8000, data_size))
debt_to_income_ratios = np.random.uniform(0.1, 0.6, data_size)

# Normalize large-scale features using log transformation
annual_incomes = np.log1p(annual_incomes)
loan_amounts = np.log1p(loan_amounts)
collateral_values = np.log1p(collateral_values)

# Define weights based on the World Bank Creditworthiness Methodology and PAS framework
weights = {
    'credit_score': 0.35,
    'annual_income': 0.25,
    'loan_amount': -0.20,
    'collateral_value': 0.20,
    'debt_to_income_ratio': -0.10
}

# Compute Weighted Score
weighted_scores = (weights['credit_score'] * credit_scores +
                   weights['annual_income'] * annual_incomes +
                   weights['loan_amount'] * loan_amounts +
                   weights['collateral_value'] * collateral_values +
                   weights['debt_to_income_ratio'] * debt_to_income_ratios)

# Risk assessment based on weighted index
credit_risks = weighted_scores < np.percentile(weighted_scores, 30)

# Create DataFrame
df = pd.DataFrame({
    'credit_score': credit_scores,
    'annual_income': annual_incomes,
    'loan_amount': loan_amounts,
    'collateral_value': collateral_values,
    'debt_to_income_ratio': debt_to_income_ratios,
    'weighted_score': weighted_scores,
    'credit_risk': credit_risks.astype(int)
})

# Handle missing values
df.fillna(df.median(), inplace=True)

# 2. Data Visualization
sns.pairplot(df, hue='credit_risk', diag_kind='kde')
plt.show()

# 3. Data Preprocessing
X = df[['credit_score', 'annual_income', 'loan_amount', 'collateral_value', 'debt_to_income_ratio']]
y = df['credit_risk']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. Train Model
model = LogisticRegression()
model.fit(X_train_scaled, y_train)

# 5. Model Evaluation
y_pred = model.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
print("Classification Report:")
print(report)

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test_scaled)[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc(fpr, tpr):.2f})')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

# 6. User Input for Real-Time Credit Risk Assessment
def assess_credit_risk():
    credit_score = float(input("Enter your credit score: "))
    annual_income = float(input("Enter your annual income: "))
    loan_amount = float(input("Enter your loan amount: "))
    collateral_value = float(input("Enter your collateral value: "))
    debt_to_income_ratio = float(input("Enter your debt-to-income ratio: "))

    # Ensure values are positive before applying log transformation
    if annual_income <= 0 or loan_amount <= 0 or collateral_value <= 0:
        print("Error: Annual income, loan amount, and collateral value must be greater than zero.")
        return

    annual_income = np.log1p(annual_income)
    loan_amount = np.log1p(loan_amount)
    collateral_value = np.log1p(collateral_value)

    user_data = np.array([[credit_score, annual_income, loan_amount, collateral_value, debt_to_income_ratio]])
    user_weighted_score = (weights['credit_score'] * credit_score +
                           weights['annual_income'] * annual_income +
                           weights['loan_amount'] * loan_amount +
                           weights['collateral_value'] * collateral_value +
                           weights['debt_to_income_ratio'] * debt_to_income_ratio)
    user_data_scaled = scaler.transform(user_data)
    risk_prediction = model.predict(user_data_scaled)[0]
    risk_prob = model.predict_proba(user_data_scaled)[0][1]

    print("\n--- Credit Risk Assessment ---")
    print(f"Weighted Score: {user_weighted_score:.2f}")
    print(f"Predicted Risk Level: {'High Risk' if risk_prediction == 1 else 'Low Risk'}")
    print(f"Risk Probability: {risk_prob:.2f}")

    # Recommendations based on risk
    if risk_prediction == 1:
        print("Recommendation: Improve credit score, increase collateral, or reduce loan amount.")
    else:
        print("Recommendation: Your credit profile looks good for loan approval.")

assess_credit_risk()

"""# ESG Score Calculation"""

def calculate_esg_score(carbon_emission, employee_satisfaction, diversity_score, social_contributions, policy_violations):
    """
    Calculates the ESG score based on environmental, social, and governance factors.

    Parameters:
        carbon_emission (float): Carbon emissions in tons.
        employee_satisfaction (float): Employee satisfaction score (0-100).
        diversity_score (float): Workplace diversity score (0-100).
        social_contributions (float): Corporate social responsibility score (0-100).
        policy_violations (int): Number of governance policy violations.

    Returns:
        float: ESG score (0-100)
    """
    # Compute Environmental Score
    environmental_score = max(0, 100 - (carbon_emission * 2))

    # Compute Social Score
    social_score = (employee_satisfaction + diversity_score + social_contributions) / 3

    # Compute Governance Score
    governance_score = max(0, 100 - (policy_violations * 5))

    # Final ESG Score using weights
    weights = {'environmental': 0.40, 'social': 0.35, 'governance': 0.25}
    esg_score = (weights['environmental'] * environmental_score +
                 weights['social'] * social_score +
                 weights['governance'] * governance_score)

    return round(esg_score, 2)

# Example usage
carbon_emission = float(input("Enter Carbon Emission (tons): "))
employee_satisfaction = float(input("Enter Employee Satisfaction (0-100): "))
diversity_score = float(input("Enter Diversity Score (0-100): "))
social_contributions = float(input("Enter Social Contributions Score (0-100): "))
policy_violations = int(input("Enter Number of Policy Violations: "))

esg_score = calculate_esg_score(carbon_emission, employee_satisfaction, diversity_score, social_contributions, policy_violations)
print(f"Calculated ESG Score: {esg_score}")

"""# Fraud Detection"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import xgboost as xgb
from sklearn.ensemble import IsolationForest

# 1. Generate Synthetic Data
np.random.seed(0)
data_size = 1000
credit_scores = np.random.normal(600, 100, data_size)
annual_incomes = np.abs(np.random.normal(50000, 15000, data_size))  # Ensure positive values
loan_amounts = np.abs(np.random.normal(20000, 7000, data_size))
collateral_values = np.abs(np.random.normal(25000, 8000, data_size))
debt_to_income_ratios = np.random.uniform(0.1, 0.6, data_size)
esg_scores = np.random.uniform(0, 100, data_size)  # Simulated ESG score between 0 and 100

# Normalize large-scale features using log transformation
annual_incomes = np.log1p(annual_incomes)
loan_amounts = np.log1p(loan_amounts)
collateral_values = np.log1p(collateral_values)

# Define weights based on the World Bank Creditworthiness Methodology and PAS framework
weights = {
    'credit_score': 0.30,
    'annual_income': 0.20,
    'loan_amount': -0.15,
    'collateral_value': 0.15,
    'debt_to_income_ratio': -0.10,
    'esg_score': 0.30
}

# Compute Weighted Score
weighted_scores = (weights['credit_score'] * credit_scores +
                   weights['annual_income'] * annual_incomes +
                   weights['loan_amount'] * loan_amounts +
                   weights['collateral_value'] * collateral_values +
                   weights['debt_to_income_ratio'] * debt_to_income_ratios +
                   weights['esg_score'] * esg_scores)

# Risk assessment based on weighted index
credit_risks = weighted_scores < np.percentile(weighted_scores, 30)

# Create DataFrame
df = pd.DataFrame({
    'credit_score': credit_scores,
    'annual_income': annual_incomes,
    'loan_amount': loan_amounts,
    'collateral_value': collateral_values,
    'debt_to_income_ratio': debt_to_income_ratios,
    'esg_score': esg_scores,
    'weighted_score': weighted_scores,
    'credit_risk': credit_risks.astype(int)
})

# Handle missing values
df.fillna(df.median(), inplace=True)

# 3. Data Preprocessing
X = df[['credit_score', 'annual_income', 'loan_amount', 'collateral_value', 'debt_to_income_ratio', 'esg_score']]
y = df['credit_risk']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. Train Credit Risk Model
credit_risk_model = LogisticRegression()
credit_risk_model.fit(X_train_scaled, y_train)

# 5. Model Evaluation
y_pred = credit_risk_model.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print(f"Credit Risk Model Accuracy: {accuracy:.2f}")
print("Classification Report:")
print(report)

# 6. AI-Powered Loan Matching using XGBoost
# Generate synthetic bank approval data
partner_banks = np.random.choice(['Bank A', 'Bank B', 'Bank C', 'Bank D'], size=data_size)
interest_rates = np.random.uniform(3, 10, data_size)  # Random interest rates between 3% and 10%
loan_approval = np.random.choice([0, 1], size=data_size, p=[0.3, 0.7])  # 70% chance of approval

# Add bank matching data to DataFrame
df['partner_bank'] = partner_banks
df['interest_rate'] = interest_rates
df['loan_approval'] = loan_approval

# Encode categorical bank names
df['partner_bank'] = pd.factorize(df['partner_bank'])[0]

# Prepare data for XGBoost Model
X_bank = df[['credit_score', 'annual_income', 'loan_amount', 'collateral_value', 'debt_to_income_ratio', 'esg_score', 'partner_bank']]
y_bank = df['loan_approval']
X_train_bank, X_test_bank, y_train_bank, y_test_bank = train_test_split(X_bank, y_bank, test_size=0.2, random_state=42)

# Train XGBoost Model
xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')
xgb_model.fit(X_train_bank, y_train_bank)

# 7. Fraud Detection using Isolation Forest
fraud_detector = IsolationForest(contamination=0.02, random_state=42)  # Reduced contamination rate
df['fraud_score'] = fraud_detector.fit_predict(X)
df['fraudulent'] = df['fraud_score'] == -1

# 8. User Input for Loan Matching
def loan_matching():
    credit_score = float(input("Enter your credit score: "))
    annual_income = float(input("Enter your annual income: "))
    loan_amount = float(input("Enter your loan amount: "))
    collateral_value = float(input("Enter your collateral value: "))
    debt_to_income_ratio = float(input("Enter your debt-to-income ratio: "))
    esg_score = float(input("Enter your ESG score: "))

    annual_income = np.log1p(annual_income)
    loan_amount = np.log1p(loan_amount)
    collateral_value = np.log1p(collateral_value)

    user_data = np.array([[credit_score, annual_income, loan_amount, collateral_value, debt_to_income_ratio, esg_score, 0]])
    user_data_scaled = scaler.transform(user_data[:, :-1])  # Ignore partner bank for scaling
    risk_prediction = credit_risk_model.predict(user_data_scaled)[0]
    loan_approval_prediction = xgb_model.predict(user_data)[0]
    interest_rate_prediction = xgb_model.predict_proba(user_data)[0][1] * 10  # Adjusting interest rate
    fraud_prediction = fraud_detector.predict(user_data[:, :-1])[0]

    print("\n--- Loan Matching Results ---")
    print(f"Predicted Risk Level: {'High Risk' if risk_prediction == 1 else 'Low Risk'}")
    print(f"Loan Approval Probability: {loan_approval_prediction:.2f}")
    print(f"Suggested Interest Rate: {interest_rate_prediction:.2f}%")
    print(f"Fraud Detection: {'Potential Fraud' if fraud_prediction == -1 else 'No Fraud Detected'}")

    if risk_prediction == 1 or fraud_prediction == -1:
        print("Recommendation: Improve credit score, increase collateral, or reduce loan amount.")
    else:
        print("Recommendation: Your credit profile looks good for loan approval.")

loan_matching()